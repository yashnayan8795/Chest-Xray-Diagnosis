chest-xray-diagnosis/
│
├── app/
│   └── app.py

import streamlit as st
from PIL import Image
import numpy as np
import torch

# Placeholder for the model loading function
def load_model(model_path):
    # TODO: Load your trained PyTorch model
    print(f"Loading model from {model_path}")
    return None

# Placeholder for the prediction function
def predict(model, image):
    # TODO: Preprocess the image and get a prediction from the model
    # Returning a dummy prediction
    return "Normal", 0.95

st.title("Chest X-Ray Disease Detection")
st.write("Upload a chest X-ray image to classify it as Normal, Pneumonia, or Tuberculosis.")

uploaded_file = st.file_uploader("Choose an X-ray image...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption='Uploaded X-ray', use_column_width=True)
    st.write("")
    st.write("Classifying...")

    # model = load_model('models/your_model.pt') # Uncomment when model is ready
    # if model:
    #     label, confidence = predict(model, image)
    #     st.write(f"Prediction: **{label}** with {confidence:.2f} confidence")
    # else:
    #     st.write("Model not loaded.")

    # Using dummy prediction for now
    label, confidence = "Normal", 0.95 
    st.write(f"Prediction: **{label}** with {confidence:.2f} confidence")

    # Placeholder for Grad-CAM visualization
    st.write("### Grad-CAM Explanation")
    st.write("_Grad-CAM visualization will be shown here._")

│
├── data/
│   ├── raw/
│   │   ├── normal/
│   │   └── pneumonia/
│   │   |   └── (images from Kaggle dataset)
│   │   └── tb/ -empty
│   └── split/
│       ├── train/
│       │   ├── normal/
│       │   └── pneumonia/
│       ├── val/
│       │   ├── normal/
│       │   └── pneumonia/
│		│   └── tb/ (empty)
│       └── test/
│           ├── normal/
│           └── pneumonia/
│			└── tb/ (empty)
├── models/
│   └── .gitkeep
│
├── notebooks/
│   ├── 01_eda.ipynb
# This is a placeholder for Exploratory Data Analysis 

import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import numpy as np

# Define paths
split_data_dir = 'data/split'
train_dir = os.path.join(split_data_dir, 'train')
val_dir = os.path.join(split_data_dir, 'val')
test_dir = os.path.join(split_data_dir, 'test')

# Count images in each set
def count_images(directory):
    counts = {}
    for cls in os.listdir(directory):
        cls_dir = os.path.join(directory, cls)
        if os.path.isdir(cls_dir):
            counts[cls] = len(os.listdir(cls_dir))
    return counts

train_counts = count_images(train_dir)
val_counts = count_images(val_dir)
test_counts = count_images(test_dir)

# Create a DataFrame for plotting
data = {
    'Set': ['Train']*len(train_counts) + ['Validation']*len(val_counts) + ['Test']*len(test_counts),
    'Class': list(train_counts.keys()) + list(val_counts.keys()) + list(test_counts.keys()),
    'Count': list(train_counts.values()) + list(val_counts.values()) + list(test_counts.values())
}
df = pd.DataFrame(data)

# Plot class distribution
plt.figure(figsize=(10, 6))
sns.barplot(x='Set', y='Count', hue='Class', data=df)
plt.title('Class Distribution in Train, Validation, and Test Sets')
plt.show()

# Display sample images
def display_samples(directory, num_samples=3):
    plt.figure(figsize=(12, 8))
    for i, cls in enumerate(os.listdir(directory)):
        cls_dir = os.path.join(directory, cls)
        if os.path.isdir(cls_dir):
            img_names = os.listdir(cls_dir)[:num_samples]
            for j, img_name in enumerate(img_names):
                img_path = os.path.join(cls_dir, img_name)
                img = Image.open(img_path)
                plt.subplot(len(os.listdir(directory)), num_samples, i * num_samples + j + 1)
                plt.imshow(img, cmap='gray')
                plt.title(f'{cls}')
                plt.axis('off')
    plt.tight_layout()
    plt.show()

print("Displaying sample images from the training set:")
display_samples(train_dir) 
│   ├── 02_preprocessing.ipynb
│   ├── 03_model_training.ipynb
│   └── 04_gradcam_explain.ipynb
│
├── utils/
│   ├── data_utils.py
import os
import shutil
from glob import glob
from sklearn.model_selection import train_test_split
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def split_data(raw_data_dir, split_data_dir, train_size=0.7, val_size=0.15, test_size=0.15):
    """
    Splits the raw data into train, validation, and test sets for each class.
    """
    if abs(train_size + val_size + test_size - 1.0) > 1e-8:
        raise ValueError("The sum of train, val, and test sizes must be 1.")

    if os.path.exists(split_data_dir):
        logging.info(f"Split data directory '{split_data_dir}' already exists. Deleting it.")
        shutil.rmtree(split_data_dir)

    classes = [d for d in os.listdir(raw_data_dir) if os.path.isdir(os.path.join(raw_data_dir, d))]

    for cls in classes:
        # Create destination directories
        for folder in ['train', 'val', 'test']:
            os.makedirs(os.path.join(split_data_dir, folder, cls), exist_ok=True)

        # Get all image paths
        img_paths = glob(os.path.join(raw_data_dir, cls, '*.jpeg'))
        if not img_paths:
            logging.warning(f"No images found for class '{cls}', skipping.")
            continue
        
        # Split data
        train_val_paths, test_paths = train_test_split(img_paths, test_size=test_size, random_state=42)
        relative_val_size = val_size / (train_size + val_size)
        train_paths, val_paths = train_test_split(train_val_paths, test_size=relative_val_size, random_state=42)

        # Copy files
        for src_path in train_paths:
            shutil.copy(src_path, os.path.join(split_data_dir, 'train', cls))
        for src_path in val_paths:
            shutil.copy(src_path, os.path.join(split_data_dir, 'val', cls))
        for src_path in test_paths:
            shutil.copy(src_path, os.path.join(split_data_dir, 'test', cls))

        logging.info(f"Split {len(img_paths)} images of class '{cls}' into {len(train_paths)} train, {len(val_paths)} val, and {len(test_paths)} test.")

if __name__ == '__main__':
    raw_data_path = 'data/raw'
    split_data_path = 'data/split'
    split_data(raw_data_path, split_data_path)
    logging.info("Data splitting complete.")

│   └── grad_cam_utils.py
import torch
from pytorch_grad_cam import GradCAM
from pytorch_grad_cam.utils.image import show_cam_on_image
from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget

def generate_grad_cam(model, image_tensor, target_layer):
    """
    Generates a Grad-CAM visualization for a given model and image.
    """
    # TODO: Complete the implementation for Grad-CAM visualization
    print("Grad-CAM generation logic needs to be implemented.")
    return None

if __name__ == '__main__':
    # This is a placeholder for testing the Grad-CAM utility
    pass 
│
├── .gitignore
├── README.md
├── requirements.txt
└── venv/